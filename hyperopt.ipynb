{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1711639686314,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"STzhSkApiLIn"},"outputs":[],"source":["# !pip install SMOTE"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711639687955,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"fi10uuDuiLIo"},"outputs":[],"source":["# !pip install imbalanced-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711639688300,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"IbccvZDCiLIo"},"outputs":[],"source":["# !pip install -U scikit-learn imbalanced-learn"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711639689100,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"LluOvvqwiLIp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in c:\\users\\blobb\\appdata\\roaming\\python\\python310\\site-packages (2.10.1)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (24.3.7)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: numpy>=1.20 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (3.19.6)\n","Requirement already satisfied: setuptools in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (68.2.2)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (0.31.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (1.62.1)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (2.10.1)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n"]}],"source":["# pip install tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711639689983,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"IJn6REU8iLIp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting xgboost\n","  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n","Requirement already satisfied: numpy in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from xgboost) (1.25.2)\n","Requirement already satisfied: scipy in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from xgboost) (1.11.4)\n","Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n","   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/99.8 MB 1.4 MB/s eta 0:01:14\n","   ---------------------------------------- 0.7/99.8 MB 11.9 MB/s eta 0:00:09\n","    --------------------------------------- 2.1/99.8 MB 19.4 MB/s eta 0:00:06\n","   - -------------------------------------- 3.9/99.8 MB 24.7 MB/s eta 0:00:04\n","   -- ------------------------------------- 5.7/99.8 MB 27.8 MB/s eta 0:00:04\n","   --- ------------------------------------ 7.5/99.8 MB 30.1 MB/s eta 0:00:04\n","   --- ------------------------------------ 9.5/99.8 MB 31.8 MB/s eta 0:00:03\n","   ---- ----------------------------------- 11.4/99.8 MB 38.5 MB/s eta 0:00:03\n","   ----- ---------------------------------- 13.4/99.8 MB 40.9 MB/s eta 0:00:03\n","   ----- ---------------------------------- 14.9/99.8 MB 38.6 MB/s eta 0:00:03\n","   ------ --------------------------------- 16.5/99.8 MB 38.6 MB/s eta 0:00:03\n","   ------- -------------------------------- 17.9/99.8 MB 36.4 MB/s eta 0:00:03\n","   ------- -------------------------------- 19.2/99.8 MB 34.4 MB/s eta 0:00:03\n","   -------- ------------------------------- 20.7/99.8 MB 34.4 MB/s eta 0:00:03\n","   -------- ------------------------------- 22.0/99.8 MB 32.7 MB/s eta 0:00:03\n","   --------- ------------------------------ 23.4/99.8 MB 31.1 MB/s eta 0:00:03\n","   --------- ------------------------------ 23.7/99.8 MB 28.4 MB/s eta 0:00:03\n","   --------- ------------------------------ 23.8/99.8 MB 25.1 MB/s eta 0:00:04\n","   --------- ------------------------------ 23.9/99.8 MB 22.6 MB/s eta 0:00:04\n","   --------- ------------------------------ 24.0/99.8 MB 20.5 MB/s eta 0:00:04\n","   --------- ------------------------------ 24.1/99.8 MB 19.3 MB/s eta 0:00:04\n","   --------- ------------------------------ 24.8/99.8 MB 17.7 MB/s eta 0:00:05\n","   ---------- ----------------------------- 26.4/99.8 MB 17.7 MB/s eta 0:00:05\n","   ----------- ---------------------------- 28.2/99.8 MB 18.7 MB/s eta 0:00:04\n","   ------------ --------------------------- 30.2/99.8 MB 19.3 MB/s eta 0:00:04\n","   ------------ --------------------------- 32.2/99.8 MB 19.9 MB/s eta 0:00:04\n","   ------------- -------------------------- 33.9/99.8 MB 21.1 MB/s eta 0:00:04\n","   -------------- ------------------------- 35.2/99.8 MB 38.5 MB/s eta 0:00:02\n","   -------------- ------------------------- 36.3/99.8 MB 36.4 MB/s eta 0:00:02\n","   -------------- ------------------------- 37.2/99.8 MB 32.7 MB/s eta 0:00:02\n","   --------------- ------------------------ 38.4/99.8 MB 31.2 MB/s eta 0:00:02\n","   --------------- ------------------------ 39.7/99.8 MB 29.7 MB/s eta 0:00:03\n","   ---------------- ----------------------- 41.1/99.8 MB 28.5 MB/s eta 0:00:03\n","   ----------------- ---------------------- 42.5/99.8 MB 27.3 MB/s eta 0:00:03\n","   ----------------- ---------------------- 43.9/99.8 MB 27.3 MB/s eta 0:00:03\n","   ------------------ --------------------- 45.3/99.8 MB 27.3 MB/s eta 0:00:02\n","   ------------------ --------------------- 46.7/99.8 MB 27.3 MB/s eta 0:00:02\n","   ------------------- -------------------- 48.0/99.8 MB 29.7 MB/s eta 0:00:02\n","   ------------------- -------------------- 49.4/99.8 MB 29.7 MB/s eta 0:00:02\n","   -------------------- ------------------- 50.8/99.8 MB 29.7 MB/s eta 0:00:02\n","   -------------------- ------------------- 52.3/99.8 MB 29.8 MB/s eta 0:00:02\n","   --------------------- ------------------ 53.6/99.8 MB 29.8 MB/s eta 0:00:02\n","   ---------------------- ----------------- 54.9/99.8 MB 29.7 MB/s eta 0:00:02\n","   ---------------------- ----------------- 56.4/99.8 MB 29.7 MB/s eta 0:00:02\n","   ----------------------- ---------------- 57.8/99.8 MB 29.7 MB/s eta 0:00:02\n","   ----------------------- ---------------- 59.2/99.8 MB 29.7 MB/s eta 0:00:02\n","   ------------------------ --------------- 60.6/99.8 MB 29.7 MB/s eta 0:00:02\n","   ------------------------ --------------- 61.9/99.8 MB 29.7 MB/s eta 0:00:02\n","   ------------------------- -------------- 63.4/99.8 MB 29.8 MB/s eta 0:00:02\n","   ------------------------- -------------- 64.8/99.8 MB 29.8 MB/s eta 0:00:02\n","   -------------------------- ------------- 66.8/99.8 MB 31.2 MB/s eta 0:00:02\n","   --------------------------- ------------ 68.8/99.8 MB 32.8 MB/s eta 0:00:01\n","   ---------------------------- ----------- 70.2/99.8 MB 32.7 MB/s eta 0:00:01\n","   ---------------------------- ----------- 71.5/99.8 MB 32.7 MB/s eta 0:00:01\n","   ----------------------------- ---------- 72.9/99.8 MB 32.7 MB/s eta 0:00:01\n","   ----------------------------- ---------- 74.2/99.8 MB 32.7 MB/s eta 0:00:01\n","   ------------------------------ --------- 75.6/99.8 MB 32.8 MB/s eta 0:00:01\n","   ------------------------------ --------- 77.0/99.8 MB 31.2 MB/s eta 0:00:01\n","   ------------------------------- -------- 78.4/99.8 MB 29.7 MB/s eta 0:00:01\n","   -------------------------------- ------- 79.8/99.8 MB 28.5 MB/s eta 0:00:01\n","   -------------------------------- ------- 81.2/99.8 MB 28.5 MB/s eta 0:00:01\n","   --------------------------------- ------ 83.2/99.8 MB 31.2 MB/s eta 0:00:01\n","   ---------------------------------- ----- 85.2/99.8 MB 34.4 MB/s eta 0:00:01\n","   ---------------------------------- ----- 87.2/99.8 MB 36.3 MB/s eta 0:00:01\n","   ----------------------------------- ---- 89.2/99.8 MB 38.6 MB/s eta 0:00:01\n","   ------------------------------------ --- 91.2/99.8 MB 40.9 MB/s eta 0:00:01\n","   ------------------------------------- -- 92.6/99.8 MB 40.9 MB/s eta 0:00:01\n","   ------------------------------------- -- 93.8/99.8 MB 36.4 MB/s eta 0:00:01\n","   -------------------------------------- - 95.1/99.8 MB 34.4 MB/s eta 0:00:01\n","   -------------------------------------- - 96.7/99.8 MB 34.4 MB/s eta 0:00:01\n","   ---------------------------------------  98.0/99.8 MB 32.7 MB/s eta 0:00:01\n","   ---------------------------------------  99.3/99.8 MB 31.1 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 29.7 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 29.7 MB/s eta 0:00:01\n","   ---------------------------------------- 99.8/99.8 MB 23.3 MB/s eta 0:00:00\n","Installing collected packages: xgboost\n","Successfully installed xgboost-2.0.3\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n"]}],"source":["# pip install xgboost"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":534,"status":"ok","timestamp":1711639691169,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"ckTbwOmdiLIp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gensim in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (4.3.2)\n","Requirement already satisfied: numpy>=1.18.5 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from gensim) (1.25.2)\n","Requirement already satisfied: scipy>=1.7.0 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from gensim) (1.11.4)\n","Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from gensim) (6.4.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n"]}],"source":["# pip install gensim"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711639691681,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"oevV5NR8iLIp"},"outputs":[],"source":["# pip install numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711639692114,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"Q3P0ngz3iLIp"},"outputs":[],"source":["# pip install pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711639693174,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"HecUwZCHiLIp"},"outputs":[],"source":["# pip install matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711639694660,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"a-kkKglmiLIp"},"outputs":[],"source":["# pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711639695127,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"-p3f8fiWiLIp"},"outputs":[],"source":["# pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711639695514,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"GUuKn0bLiLIp"},"outputs":[],"source":["# import nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711639696551,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"yCyZywvfiLIp"},"outputs":[],"source":["# nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711639697781,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"we0uov_-nCET"},"outputs":[],"source":["# nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711639698108,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"n6b1kwlEnQAC"},"outputs":[],"source":["# nltk.download('wordnet')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting hyperopt\n","  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: numpy in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from hyperopt) (1.25.2)\n","Requirement already satisfied: scipy in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from hyperopt) (1.11.4)\n","Requirement already satisfied: six in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from hyperopt) (1.16.0)\n","Requirement already satisfied: networkx>=2.2 in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from hyperopt) (3.1)\n","Collecting future (from hyperopt)\n","  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: tqdm in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from hyperopt) (4.65.0)\n","Collecting cloudpickle (from hyperopt)\n","  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n","Collecting py4j (from hyperopt)\n","  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: colorama in c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n","Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n","   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n","   ---- ----------------------------------- 0.2/1.6 MB 5.3 MB/s eta 0:00:01\n","   ------------------- -------------------- 0.8/1.6 MB 9.6 MB/s eta 0:00:01\n","   ---------------------------------------  1.6/1.6 MB 12.5 MB/s eta 0:00:01\n","   ---------------------------------------- 1.6/1.6 MB 12.6 MB/s eta 0:00:00\n","Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n","Downloading future-1.0.0-py3-none-any.whl (491 kB)\n","   ---------------------------------------- 0.0/491.3 kB ? eta -:--:--\n","   --------------------------------------- 491.3/491.3 kB 30.1 MB/s eta 0:00:00\n","Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n","   ---------------------------------------- 0.0/200.5 kB ? eta -:--:--\n","   ---------------------------------------- 200.5/200.5 kB ? eta 0:00:00\n","Installing collected packages: py4j, future, cloudpickle, hyperopt\n","Successfully installed cloudpickle-3.0.0 future-1.0.0 hyperopt-0.2.7 py4j-0.10.9.7\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -uggingface-hub (c:\\users\\blobb\\.conda\\envs\\torch\\lib\\site-packages)\n"]}],"source":["#  pip install hyperopt"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13157,"status":"ok","timestamp":1711639712882,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"0Y-IuX1SiLIq"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics import classification_report\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.over_sampling import SMOTE\n","from collections import Counter\n","from imblearn.under_sampling import RandomUnderSampler\n","# import keras.preprocessing.text Tokenizer\n","from keras.layers import Embedding, LSTM, Dense\n","from keras.models import Sequential\n","from imblearn.under_sampling import TomekLinks\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n","import xgboost as xgb\n","from gensim.models import KeyedVectors\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import MaxAbsScaler\n","from sklearn.feature_extraction.text import HashingVectorizer\n","# import spacy\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n","from sklearn.preprocessing import Normalizer\n","from gensim.models import KeyedVectors\n","from sklearn.pipeline import Pipeline\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","import re\n","from sklearn.svm import SVC\n","from sklearn.linear_model import SGDClassifier\n","from gensim.models import KeyedVectors\n","import random\n","import tensorflow as tf\n","import os\n","from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2271,"status":"ok","timestamp":1711639773147,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"gsifKTb3iLIq"},"outputs":[],"source":["train = pd.read_csv(\"./train.csv\")\n","test = pd.read_csv(\"./test.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711639775095,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"wbmxlG2iiLIq","outputId":"0296d3be-7164-4c40-9bed-5e5258453e9d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>overall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>370863.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4.566600</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.930377</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>5.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             overall\n","count  370863.000000\n","mean        4.566600\n","std         0.930377\n","min         1.000000\n","25%         5.000000\n","50%         5.000000\n","75%         5.000000\n","max         5.000000"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train.describe()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":532,"status":"ok","timestamp":1711639778597,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"xmh09hWimN01"},"outputs":[],"source":["def preprocess(text):\n","    pattern = r\"[^\\w\\s]\"\n","    text = [''.join([char if char.isalnum() else ' ' for char in word]) for word in text.split()]\n","    text = ' '.join(text)\n","    text =  re.sub(pattern,\" \",text)\n","     # used word_tokenize function to tokenize the text, gives list\n","\n","    tokenized_text = word_tokenize(text.lower())\n","    # get the stop words\n","    stop_words = set(stopwords.words('english'))\n","    # removed stop words\n","    tokenized_text = [word for word in tokenized_text if word not in stop_words]\n","    # applying stemming\n","    # stemmer = PorterStemmer()\n","    # tokenized_text = [stemmer.stem(word) for word in tokenized_text]\n","    # applying lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    tokenized_text = [lemmatizer.lemmatize(word) for word in tokenized_text]\n","\n","    preprocessed_text = ' '.join(tokenized_text)\n","\n","    return preprocessed_text"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def reset_random_seeds(SEED=42):\n","   os.environ['PYTHONHASHSEED']=str(SEED)\n","   tf.random.set_seed(SEED)\n","   np.random.seed(SEED)\n","   random.seed(SEED)\n","reset_random_seeds(SEED=42)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"executionInfo":{"elapsed":846,"status":"ok","timestamp":1711639810554,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"AHL99EKQiLIq","outputId":"1325778d-35b6-4d80-9dbc-3c5f705eb19b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>overall</th>\n","      <th>Review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>I love these glitter pens. They sparkle deligh...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>It works well with my machine.  I use mostly c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>This is a great assortment of colors, though t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>Just what I was looking for.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>I make 400 birds for the hospital each month.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>not very sharp</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5</td>\n","      <td>Its just a replacement blade</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5</td>\n","      <td>Great value,</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>3</td>\n","      <td>It is just okay for me.  The plastic is a bit ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5</td>\n","      <td>Always happy when I find a great priced art gi...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>I only received on piece of fabric.  Wasn't I ...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>5</td>\n","      <td>My favorite color being red, one of my favorit...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3</td>\n","      <td>Good marking pen for light colored fabric. Lin...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>3</td>\n","      <td>These fasteners work fine but the spring is a ...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5</td>\n","      <td>Love these for all my needles</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>5</td>\n","      <td>Basic for sewing.  Top  quality</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>4</td>\n","      <td>Was a gift for someone in New Zealand at a chi...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>5</td>\n","      <td>Great products and will order again! These are...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>2</td>\n","      <td>The spools have cuts on both sides and now mat...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>5</td>\n","      <td>Awesome display.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    overall                                             Review\n","0         5  I love these glitter pens. They sparkle deligh...\n","1         5  It works well with my machine.  I use mostly c...\n","2         5  This is a great assortment of colors, though t...\n","3         5                       Just what I was looking for.\n","4         5      I make 400 birds for the hospital each month.\n","5         1                                     not very sharp\n","6         5                       Its just a replacement blade\n","7         5                                       Great value,\n","8         3  It is just okay for me.  The plastic is a bit ...\n","9         5  Always happy when I find a great priced art gi...\n","10        1  I only received on piece of fabric.  Wasn't I ...\n","11        5  My favorite color being red, one of my favorit...\n","12        3  Good marking pen for light colored fabric. Lin...\n","13        3  These fasteners work fine but the spring is a ...\n","14        5                      Love these for all my needles\n","15        5                    Basic for sewing.  Top  quality\n","16        4  Was a gift for someone in New Zealand at a chi...\n","17        5  Great products and will order again! These are...\n","18        2  The spools have cuts on both sides and now mat...\n","19        5                                   Awesome display."]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train.head(20)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1711639813596,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"vaae7dD6iLIr","outputId":"45b1019a-04de-4864-faee-8a625c1d9d49"},"outputs":[{"data":{"text/plain":["overall    0\n","Review     8\n","dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train.isnull().sum()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1711639817083,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"i960SLZ9iLIr","outputId":"d157c34d-401a-4cd2-d173-bb8e7d1b343d"},"outputs":[{"data":{"text/plain":["overall    0\n","Review     8\n","dtype: int64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train.isnull().sum()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1711639820055,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"m09EUhvriLIr","outputId":"8b2a70c6-32ec-4d46-a035-b13ff161bf61"},"outputs":[{"data":{"text/plain":["93449"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train.duplicated().sum()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":584,"status":"ok","timestamp":1711639822505,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"1Ei-xd4OiLIr"},"outputs":[],"source":["train = train.drop_duplicates()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":519,"status":"ok","timestamp":1711639824738,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"lt8ESqaMiLIr","outputId":"acf76289-554b-455d-a021-229c471c7605"},"outputs":[{"data":{"text/plain":["(277414, 2)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["train.shape"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":512,"status":"ok","timestamp":1711639826798,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"EkEJX4mMiLIr","outputId":"a5ab1cc9-4d8a-4ca4-e1ca-f8d66594d1c6"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["class_counts = train['overall'].value_counts()\n","\n","plt.bar(class_counts.index, class_counts.values)\n","plt.xlabel('Class')\n","plt.ylabel('Number of Samples')\n","plt.title('Histogram of Sample Counts per Class')\n","plt.show()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1711639829602,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"djVxNvSKiLIr","outputId":"dbdc9f0e-8c86-4b36-a857-210c579b0110"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>123622.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>61810.500000</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>35686.741826</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>30905.250000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>61810.500000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>92715.750000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>123621.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  id\n","count  123622.000000\n","mean    61810.500000\n","std     35686.741826\n","min         0.000000\n","25%     30905.250000\n","50%     61810.500000\n","75%     92715.750000\n","max    123621.000000"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["test.describe()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1711639832648,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"Du9nBRF5iLIr","outputId":"a80100b7-52b7-45aa-e65a-1a43663c9fe0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Wonderful asst. of  wood carving tools</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Pretty lace with 4 way stretch. I was exactly ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>This is a quick and easy way to start a crazy ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>This is my favorite journals, the pages are ve...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I bought this for a costume i was making. i wa...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>Great idea but they don't cut well</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>Love this thread.</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>GOOD REUSABLE PRODUCT.  MADE BAR LOTION WITH T...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>After trial and error with various brands of a...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>They are really smelly - like a vinyl shower c...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>Everything you need to get started.</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>Gave as a gift  and bought one for myself.  Ac...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>works as described</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>Great Product -- as adertised.  Just love it -...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>I love these hooks. The handles feel nice when...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>Love these.</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>Love just about anything to do with stamps and...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>this is fantastic thread lube. I am using it w...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>thanks</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>The Velcro closure comes open when you try to ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    id                                             Review\n","0    0             Wonderful asst. of  wood carving tools\n","1    1  Pretty lace with 4 way stretch. I was exactly ...\n","2    2  This is a quick and easy way to start a crazy ...\n","3    3  This is my favorite journals, the pages are ve...\n","4    4  I bought this for a costume i was making. i wa...\n","5    5                 Great idea but they don't cut well\n","6    6                                  Love this thread.\n","7    7  GOOD REUSABLE PRODUCT.  MADE BAR LOTION WITH T...\n","8    8  After trial and error with various brands of a...\n","9    9  They are really smelly - like a vinyl shower c...\n","10  10                Everything you need to get started.\n","11  11  Gave as a gift  and bought one for myself.  Ac...\n","12  12                                 works as described\n","13  13  Great Product -- as adertised.  Just love it -...\n","14  14  I love these hooks. The handles feel nice when...\n","15  15                                        Love these.\n","16  16  Love just about anything to do with stamps and...\n","17  17  this is fantastic thread lube. I am using it w...\n","18  18                                             thanks\n","19  19  The Velcro closure comes open when you try to ..."]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["test.head(20)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711639835724,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"oP3b2cX8iLIr","outputId":"46675ad9-0ae7-4aa5-d109-48005395d880"},"outputs":[{"data":{"text/plain":["id        0\n","Review    4\n","dtype: int64"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["test.isnull().sum()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1711639838606,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"kIXdEjAliLIs","outputId":"59320635-c723-4dec-e695-490cffcdbcc8"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["test.duplicated().sum()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":646,"status":"ok","timestamp":1711639847395,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"fyYON_FZiLIs","outputId":"a473e7e9-8a23-4000-8f32-f98294807011"},"outputs":[{"data":{"text/plain":["(123622, 2)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["test.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1711639851899,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"Oo8QV653iLIs"},"outputs":[],"source":["train[\"Review\"]= train[\"Review\"].astype(str)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":154208,"status":"ok","timestamp":1711640124598,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"Jcpmf08ZiLIs"},"outputs":[],"source":["train[\"Review\"] = train[\"Review\"].apply(preprocess)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1711640130851,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"esXSL6P0iLIs","outputId":"3aa82ddd-f124-47e1-af7a-e0119344ca52"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>overall</th>\n","      <th>Review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>love glitter pen sparkle delightfully page bri...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>work well machine use mostly cone</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>great assortment color though lot pink mix sti...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>looking</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>make 400 bird hospital month</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>370856</th>\n","      <td>5</td>\n","      <td>perfect application bottle dispensing powdered...</td>\n","    </tr>\n","    <tr>\n","      <th>370857</th>\n","      <td>4</td>\n","      <td>mainly purchased roll pencil case going gift s...</td>\n","    </tr>\n","    <tr>\n","      <th>370858</th>\n","      <td>5</td>\n","      <td>love dy make great background card</td>\n","    </tr>\n","    <tr>\n","      <th>370859</th>\n","      <td>5</td>\n","      <td>love darice embossing folder darcie folder rea...</td>\n","    </tr>\n","    <tr>\n","      <th>370860</th>\n","      <td>5</td>\n","      <td>ordered add earthy marker previously ordered w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>277414 rows × 2 columns</p>\n","</div>"],"text/plain":["        overall                                             Review\n","0             5  love glitter pen sparkle delightfully page bri...\n","1             5                  work well machine use mostly cone\n","2             5  great assortment color though lot pink mix sti...\n","3             5                                            looking\n","4             5                       make 400 bird hospital month\n","...         ...                                                ...\n","370856        5  perfect application bottle dispensing powdered...\n","370857        4  mainly purchased roll pencil case going gift s...\n","370858        5                 love dy make great background card\n","370859        5  love darice embossing folder darcie folder rea...\n","370860        5  ordered add earthy marker previously ordered w...\n","\n","[277414 rows x 2 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["train"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1711640134423,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"awR3j3bsiLIs","outputId":"cccf64e4-64f4-413b-af05-a9828ac515b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original class distribution: Counter({5: 143171, 4: 25754, 3: 12802, 1: 6567, 2: 5895})\n"]}],"source":["y = train[\"overall\"]\n","X_train, X_test, y_train, y_test = train_test_split(train[\"Review\"], y, stratify=y,test_size=0.3, random_state=42)\n","print('Original class distribution:', Counter(y_train))"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711640136039,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"VPyBJuAoiLIs","outputId":"18a068a9-1d5e-472b-e0de-0184216791cc"},"outputs":[{"data":{"text/plain":["(194189,)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711640138423,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"LmpWSVKuiLIt"},"outputs":[],"source":["def create_pipeline(classifiers,vectorizer, normalizer=None, reduction= False, feature_selection=True,k=1000,balancing=False ):\n","     # start building the pipeline, first step -> vectorization\n","    step =[(\"vectorizer\",vectorizer)]\n","     # if dimensionality reduction is requested add a TruncatedSVD step to the pipeline\n","    if normalizer:\n","        step.append((\"normalizer\",normalizer))\n","    # if feature selection is requested add a SelectKBest step to the pipeline\n","    if feature_selection:\n","        step.append(('feature_selection', SelectKBest(chi2, k=k)))\n","    # add the classifier to the pipeline\n","    step.append((\"classifier\",classifiers))\n","\n","        # pipeline object with the steps prepared above and assign it to the corresponding classifier name in the models dict\n","    models = Pipeline(step)\n","    return models"]},{"cell_type":"markdown","metadata":{"id":"x5e9hqzsiLIt"},"source":["## Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"T96tXmlOiLIu"},"source":["### Comparing Ngram Features"]},{"cell_type":"markdown","metadata":{},"source":["#### Unigram"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def logistic_hyperparameter(ngram):\n","    space = {\n","        'C': hp.loguniform('C', np.log(0.01), np.log(10)),\n","        'penalty': hp.choice('penalty', ['l2']),\n","        'k':hp.choice('k', np.arange(8000, 35000, 1000, dtype=int)),\n","        'class_weight': hp.choice('class_weight', ['balanced', {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}]),\n","        'solver': hp.choice('solver',['newton-cg', 'lbfgs', 'liblinear','saga']),\n","        'max_iter': hp.choice('max_iter',np.arange(1000, 8000, 500, dtype=int))\n","    }\n","\n","    def objective(params):\n","        k = params.pop('k')\n","        classifier = LogisticRegression(**params)\n","        vectorizer = TfidfVectorizer(ngram_range=ngram)\n","        \n","        model = create_pipeline(classifier, vectorizer, feature_selection=True, k=k)\n","        score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n","        print(f\"\\nTrial completed:\")\n","        print(f\"Params: {params} features:{k}\")\n","        print(f\"Accuracy: {score}, Loss: {-score}\")\n","        return {'loss': -score, 'status': STATUS_OK}\n","\n","    trials = Trials()\n","    best = fmin(fn=objective,\n","                space=space,\n","                algo=tpe.suggest,\n","                max_evals=50,\n","                trials=trials)\n","    logistic = best\n","    print(\"Best hyperparameters:\", best)\n","    return logistic"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                      \n","Trial completed:\n","Params: {'C': 5.772388108015175, 'class_weight': 'balanced', 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs'} features:26000\n","Accuracy: 0.6160132724403082, Loss: -0.6160132724403082\n","  2%|▏         | 1/50 [01:34<1:17:02, 94.33s/trial, best loss: -0.6160132724403082]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                   \n","Trial completed:\n","Params: {'C': 0.41794305812496335, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'saga'} features:10000\n","Accuracy: 0.6218016989072903, Loss: -0.6218016989072903                            \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.06559487946455038, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:9000\n","Accuracy: 0.758853489078791, Loss: -0.758853489078791                                \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.020932846390906947, 'class_weight': 'balanced', 'max_iter': 5500, 'penalty': 'l2', 'solver': 'lbfgs'} features:20000\n","Accuracy: 0.6054102020043465, Loss: -0.6054102020043465                            \n","                                                                                   \n","Trial completed:\n","Params: {'C': 0.012684063824483238, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'newton-cg'} features:21000\n","Accuracy: 0.7582973298199717, Loss: -0.7582973298199717                            \n","                                                                                   \n","Trial completed:\n","Params: {'C': 0.020243171586104662, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'liblinear'} features:26000\n","Accuracy: 0.7468239685520603, Loss: -0.7468239685520603                            \n","                                                                                   \n","Trial completed:\n","Params: {'C': 0.012307231331602423, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'lbfgs'} features:22000\n","Accuracy: 0.757947154789207, Loss: -0.757947154789207                              \n","                                                                                   \n","Trial completed:\n","Params: {'C': 0.014044232648184057, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:16000\n","Accuracy: 0.7428381631382257, Loss: -0.7428381631382257                            \n","                                                                                   \n","Trial completed:\n","Params: {'C': 0.6925481287711756, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:32000\n","Accuracy: 0.7673864172471225, Loss: -0.7673864172471225                         \n","                                                                                 \n","Trial completed:\n","Params: {'C': 0.3109829924421444, 'class_weight': 'balanced', 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear'} features:20000\n","Accuracy: 0.7429257127632498, Loss: -0.7429257127632498                          \n","                                                                                  \n","Trial completed:\n","Params: {'C': 2.0628511474064033, 'class_weight': 'balanced', 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'} features:31000\n","Accuracy: 0.7314369082770622, Loss: -0.7314369082770622                           \n","                                                                                  \n","Trial completed:\n","Params: {'C': 0.1394517209539179, 'class_weight': 'balanced', 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs'} features:18000\n","Accuracy: 0.6197261620081653, Loss: -0.6197261620081653                           \n"," 24%|██▍       | 12/50 [31:06<24:58, 39.44s/trial, best loss: -0.7673864172471225]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                  \n","Trial completed:\n","Params: {'C': 0.48382168841076517, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'saga'} features:13000\n","Accuracy: 0.6995505591089031, Loss: -0.6995505591089031                             \n"," 26%|██▌       | 13/50 [1:16:06<8:41:21, 845.43s/trial, best loss: -0.7673864172471225]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                       \n","Trial completed:\n","Params: {'C': 0.2852985606861309, 'class_weight': 'balanced', 'max_iter': 4000, 'penalty': 'l2', 'solver': 'saga'} features:34000\n","Accuracy: 0.5379864778009164, Loss: -0.5379864778009164                                \n","                                                                                         \n","Trial completed:\n","Params: {'C': 0.28702728131623423, 'class_weight': 'balanced', 'max_iter': 4000, 'penalty': 'l2', 'solver': 'newton-cg'} features:13000\n","Accuracy: 0.6207303375563665, Loss: -0.6207303375563665                                  \n","                                                                                         \n","Trial completed:\n","Params: {'C': 0.47755054293761706, 'class_weight': 'balanced', 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:31000\n","Accuracy: 0.7405517422244509, Loss: -0.7405517422244509                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 3.4216101518088573, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'lbfgs'} features:32000\n","Accuracy: 0.7493781867433086, Loss: -0.7493781867433086                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 8.851559288424598, 'class_weight': 'balanced', 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'} features:10000\n","Accuracy: 0.7263593848501375, Loss: -0.7263593848501375                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.16380064788923338, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'} features:17000\n","Accuracy: 0.7648888454047691, Loss: -0.7648888454047691                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.04987230884351744, 'class_weight': 'balanced', 'max_iter': 2500, 'penalty': 'l2', 'solver': 'lbfgs'} features:32000\n","Accuracy: 0.6139740262886724, Loss: -0.6139740262886724                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 1.0976238544044743, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'liblinear'} features:27000\n","Accuracy: 0.7670413919447098, Loss: -0.7670413919447098                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 1.2414450648880777, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'newton-cg'} features:27000\n","Accuracy: 0.757900814659366, Loss: -0.757900814659366                                \n","                                                                                     \n","Trial completed:\n","Params: {'C': 1.4561382706914607, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'liblinear'} features:11000\n","Accuracy: 0.7668766028915679, Loss: -0.7668766028915679                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.7475974112406227, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:8000\n","Accuracy: 0.7675203073997732, Loss: -0.7675203073997732                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.7534301522121929, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:8000\n","Accuracy: 0.7675151576714212, Loss: -0.7675151576714212                             \n"," 50%|█████     | 25/50 [1:50:09<21:59, 52.80s/trial, best loss: -0.7675203073997732]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                    \n","Trial completed:\n","Params: {'C': 2.4964334426207024, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'saga'} features:8000\n","Accuracy: 0.7085982698384543, Loss: -0.7085982698384543                             \n","                                                                                       \n","Trial completed:\n","Params: {'C': 5.218339934717903, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'newton-cg'} features:8000\n","Accuracy: 0.7587762562804281, Loss: -0.7587762562804281                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.826578723482321, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'liblinear'} features:8000\n","Accuracy: 0.7673967167038261, Loss: -0.7673967167038261                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.10747660555752483, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:28000\n","Accuracy: 0.7626899575416315, Loss: -0.7626899575416315                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 9.711859411943792, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:33000\n","Accuracy: 0.7564846701246751, Loss: -0.7564846701246751                                \n"," 60%|██████    | 30/50 [2:28:46<1:06:14, 198.75s/trial, best loss: -0.7675203073997732]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                       \n","Trial completed:\n","Params: {'C': 3.282861958548728, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'} features:12000\n","Accuracy: 0.5983036228893203, Loss: -0.5983036228893203                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 5.398549354506047, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'liblinear'} features:25000\n","Accuracy: 0.7608155012387081, Loss: -0.7608155012387081                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 1.7393459511182283, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'newton-cg'} features:14000\n","Accuracy: 0.7589255895187597, Loss: -0.7589255895187597                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.05876266215059258, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:29000\n","Accuracy: 0.7582818794415603, Loss: -0.7582818794415603                              \n"," 68%|██████▊   | 34/50 [2:36:47<28:44, 107.76s/trial, best loss: -0.7675203073997732]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 0.20310529422544976, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'saga'} features:30000\n","Accuracy: 0.6664484600878213, Loss: -0.6664484600878213                              \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.8259811053151901, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'lbfgs'} features:23000\n","Accuracy: 0.7608927498158874, Loss: -0.7608927498158874                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.07842841956397575, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} features:19000\n","Accuracy: 0.7605992105264097, Loss: -0.7605992105264097                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.033120139719138485, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'newton-cg'} features:15000\n","Accuracy: 0.7646828610441193, Loss: -0.7646828610441193                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.5725616510790354, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:24000\n","Accuracy: 0.7675718020313894, Loss: -0.7675718020313894                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.5795466999187212, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:24000\n","Accuracy: 0.7675512033831724, Loss: -0.7675512033831724                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.4153280704514956, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'lbfgs'} features:24000\n","Accuracy: 0.7644047884422498, Loss: -0.7644047884422498                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.2072743069779525, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:24000\n","Accuracy: 0.765712787090411, Loss: -0.765712787090411                                \n"," 84%|████████▍ | 42/50 [3:25:00<13:39, 102.39s/trial, best loss: -0.7675718020313894]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 0.09664396765009234, 'class_weight': 'balanced', 'max_iter': 6000, 'penalty': 'l2', 'solver': 'saga'} features:24000\n","Accuracy: 0.5698932344151638, Loss: -0.5698932344151638                              \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.03686912680247791, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:24000\n","Accuracy: 0.7535854258354437, Loss: -0.7535854258354437                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 1.0160679269405366, 'class_weight': 'balanced', 'max_iter': 6000, 'penalty': 'l2', 'solver': 'newton-cg'} features:9000\n","Accuracy: 0.6186910817252886, Loss: -0.6186910817252886                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.4122417941301857, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'liblinear'} features:26000\n","Accuracy: 0.7675563532441193, Loss: -0.7675563532441193                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.39490075897048965, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'lbfgs'} features:26000\n","Accuracy: 0.7645386763407837, Loss: -0.7645386763407837                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.2127149617352921, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'liblinear'} features:26000\n","Accuracy: 0.7448310698229959, Loss: -0.7448310698229959                              \n"," 96%|█████████▌| 48/50 [4:07:09<05:14, 157.32s/trial, best loss: -0.7675718020313894]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 0.018115555414668374, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'saga'} features:22000\n","Accuracy: 0.635324216086553, Loss: -0.635324216086553                                \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.11976394899346561, 'class_weight': 'balanced', 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:18000\n","Accuracy: 0.7481783233740693, Loss: -0.7481783233740693                              \n","100%|██████████| 50/50 [4:56:52<00:00, 356.26s/trial, best loss: -0.7675718020313894]\n","Best hyperparameters: {'C': 0.5725616510790354, 'class_weight': 1, 'k': 16, 'max_iter': 10, 'penalty': 0, 'solver': 2}\n"]}],"source":["best_uni = logistic_hyperparameter((1,1))"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24080,"status":"ok","timestamp":1711640166079,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"5zIVRVEmiLIu","outputId":"7200efa7-0501-40bb-e893-476de293089f"},"outputs":[],"source":["# class_weights = {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}\n","# classifier = LogisticRegression(max_iter=1000,penalty=\"l2\",C=0.13,solver= \"liblinear\" ,class_weight=class_weights)\n","# model = create_pipeline(classifier, TfidfVectorizer(ngram_range=(1,1)),k=15000)\n","# model.fit(X_train,y_train)\n","# y_pred = model.predict(X_test)\n","# print(classification_report(y_pred,y_test))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                      \n","Trial completed:\n","Params: {'C': 2.009630787530868, 'class_weight': 'balanced', 'max_iter': 7000, 'penalty': 'l2', 'solver': 'lbfgs'} features:18000\n","Accuracy: 0.6742348886039358, Loss: -0.6742348886039358\n","                                                                                 \n","Trial completed:\n","Params: {'C': 5.385846693849407, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:27000\n","Accuracy: 0.753518478173514, Loss: -0.753518478173514                            \n","                                                                                 \n","Trial completed:\n","Params: {'C': 0.017004501330583288, 'class_weight': 'balanced', 'max_iter': 4500, 'penalty': 'l2', 'solver': 'newton-cg'} features:11000\n","Accuracy: 0.3425580379642647, Loss: -0.3425580379642647                         \n","                                                                                \n","Trial completed:\n","Params: {'C': 2.330930153501652, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:31000\n","Accuracy: 0.7530035152829633, Loss: -0.7530035152829633                         \n","                                                                                \n","Trial completed:\n","Params: {'C': 2.1390270856743374, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:32000\n","Accuracy: 0.7527820825328286, Loss: -0.7527820825328286                         \n","                                                                                \n","Trial completed:\n","Params: {'C': 0.016947569705976884, 'class_weight': 'balanced', 'max_iter': 3500, 'penalty': 'l2', 'solver': 'saga'} features:31000\n","Accuracy: 0.3834872257877552, Loss: -0.3834872257877552                         \n","                                                                                \n","Trial completed:\n","Params: {'C': 2.6291851757264633, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:32000\n","Accuracy: 0.7532609975901067, Loss: -0.7532609975901067                         \n","                                                                                \n","Trial completed:\n","Params: {'C': 0.0239197291337503, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'newton-cg'} features:23000\n","Accuracy: 0.7384815815261023, Loss: -0.7384815815261023                         \n","                                                                                \n","Trial completed:\n","Params: {'C': 8.058520147878538, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'lbfgs'} features:16000\n","Accuracy: 0.7492700330336682, Loss: -0.7492700330336682                         \n","                                                                                \n","Trial completed:\n","Params: {'C': 0.07299831705112944, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'lbfgs'} features:24000\n","Accuracy: 0.7439968305369816, Loss: -0.7439968305369816                         \n","                                                                                 \n","Trial completed:\n","Params: {'C': 0.10301891563755507, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7383064935466372, Loss: -0.7383064935466372                          \n","                                                                                 \n","Trial completed:\n","Params: {'C': 0.5754954080268516, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'newton-cg'} features:17000\n","Accuracy: 0.7529417184101461, Loss: -0.7529417184101461                          \n","                                                                                 \n","Trial completed:\n","Params: {'C': 4.403469497437867, 'class_weight': 'balanced', 'max_iter': 5000, 'penalty': 'l2', 'solver': 'newton-cg'} features:8000\n","Accuracy: 0.6858884768394614, Loss: -0.6858884768394614                          \n","                                                                                 \n","Trial completed:\n","Params: {'C': 0.22207850764710754, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'lbfgs'} features:33000\n","Accuracy: 0.7503978100180191, Loss: -0.7503978100180191                          \n"," 28%|██▊       | 14/50 [08:45<24:41, 41.14s/trial, best loss: -0.753518478173514]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                 \n","Trial completed:\n","Params: {'C': 0.017345687683737662, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'saga'} features:26000\n","Accuracy: 0.6178831916042249, Loss: -0.6178831916042249                          \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.010072270769421753, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} features:23000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.4070731682888203, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'newton-cg'} features:9000\n","Accuracy: 0.6821446991113158, Loss: -0.6821446991113158                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.931380518274614, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'lbfgs'} features:26000\n","Accuracy: 0.670532323951041, Loss: -0.670532323951041                               \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.3907771848453265, 'class_weight': 'balanced', 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:31000\n","Accuracy: 0.7465201351096827, Loss: -0.7465201351096827                          \n"," 38%|███▊      | 19/50 [20:40<38:50, 75.19s/trial, best loss: -0.753518478173514]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                 \n","Trial completed:\n","Params: {'C': 3.9775476856708547, 'class_weight': 'balanced', 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga'} features:24000\n","Accuracy: 0.6773195276220666, Loss: -0.6773195276220666                          \n","                                                                                    \n","Trial completed:\n","Params: {'C': 9.950157172581845, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:22000\n","Accuracy: 0.7531065073306931, Loss: -0.7531065073306931                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.9931064675467762, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:27000\n","Accuracy: 0.7496562673008839, Loss: -0.7496562673008839                           \n","                                                                                  \n","Trial completed:\n","Params: {'C': 5.763497554959019, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:15000\n","Accuracy: 0.753791404361909, Loss: -0.753791404361909                            \n","                                                                                 \n","Trial completed:\n","Params: {'C': 5.9782713634115, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:27000\n","Accuracy: 0.753430934382674, Loss: -0.753430934382674                            \n","                                                                                 \n","Trial completed:\n","Params: {'C': 0.7245131026925931, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:34000\n","Accuracy: 0.7481113802203728, Loss: -0.7481113802203728                          \n","                                                                                 \n","Trial completed:\n","Params: {'C': 9.454656133292502, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear'} features:13000\n","Accuracy: 0.7531374049052333, Loss: -0.7531374049052333                          \n"," 52%|█████▏    | 26/50 [28:48<18:27, 46.13s/trial, best loss: -0.753791404361909]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                 \n","Trial completed:\n","Params: {'C': 0.2135175161378409, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'saga'} features:15000\n","Accuracy: 0.5318849874165198, Loss: -0.5318849874165198                          \n","                                                                                    \n","Trial completed:\n","Params: {'C': 3.644481109442405, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:15000\n","Accuracy: 0.7536266211429513, Loss: -0.7536266211429513                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.2350702323698068, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:15000\n","Accuracy: 0.7503411620779833, Loss: -0.7503411620779833                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 3.130589977369716, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'liblinear'} features:15000\n","Accuracy: 0.7534515348872224, Loss: -0.7534515348872224                           \n","                                                                                  \n","Trial completed:\n","Params: {'C': 6.860086967090467, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:14000\n","Accuracy: 0.7534927271450431, Loss: -0.7534927271450431                           \n"," 62%|██████▏   | 31/50 [45:07<29:37, 93.57s/trial, best loss: -0.753791404361909] "]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                 \n","Trial completed:\n","Params: {'C': 4.158111474877762, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'saga'} features:29000\n","Accuracy: 0.6258650351932645, Loss: -0.6258650351932645                            \n","                                                                                      \n","Trial completed:\n","Params: {'C': 0.07692066960428327, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:21000\n","Accuracy: 0.7379048234864707, Loss: -0.7379048234864707                               \n","                                                                                      \n","Trial completed:\n","Params: {'C': 1.6472864435091847, 'class_weight': 'balanced', 'max_iter': 3000, 'penalty': 'l2', 'solver': 'lbfgs'} features:12000\n","Accuracy: 0.6810117908293314, Loss: -0.6810117908293314                               \n","                                                                                      \n","Trial completed:\n","Params: {'C': 0.8588053171897511, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear'} features:19000\n","Accuracy: 0.7486469396376191, Loss: -0.7486469396376191                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.39353301284948367, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg'} features:25000\n","Accuracy: 0.7523752638050711, Loss: -0.7523752638050711                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 2.862949065143467, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:10000\n","Accuracy: 0.7524937035793104, Loss: -0.7524937035793104                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.03861537888921156, 'class_weight': 'balanced', 'max_iter': 6500, 'penalty': 'l2', 'solver': 'liblinear'} features:28000\n","Accuracy: 0.7388111565826989, Loss: -0.7388111565826989                            \n"," 76%|███████▌  | 38/50 [1:06:58<15:05, 75.48s/trial, best loss: -0.753791404361909]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                   \n","Trial completed:\n","Params: {'C': 9.903979917783886, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'saga'} features:20000\n","Accuracy: 0.7426991411575612, Loss: -0.7426991411575612                            \n","                                                                                      \n","Trial completed:\n","Params: {'C': 0.5413793914500696, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'lbfgs'} features:18000\n","Accuracy: 0.7530756081650114, Loss: -0.7530756081650114                               \n","                                                                                      \n","Trial completed:\n","Params: {'C': 0.1430112291646294, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:11000\n","Accuracy: 0.7391458824284081, Loss: -0.7391458824284081                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 5.512821273402343, 'class_weight': 'balanced', 'max_iter': 6000, 'penalty': 'l2', 'solver': 'newton-cg'} features:15000\n","Accuracy: 0.6789364861042202, Loss: -0.6789364861042202                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 2.2522867482490376, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'liblinear'} features:16000\n","Accuracy: 0.7527305849841202, Loss: -0.7527305849841202                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 3.41182439005142, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'lbfgs'} features:17000\n","Accuracy: 0.751906645817785, Loss: -0.751906645817785                               \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.2732943780021148, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'newton-cg'} features:32000\n","Accuracy: 0.7509591168836687, Loss: -0.7509591168836687                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 7.598620436265017, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:15000\n","Accuracy: 0.753631767954211, Loss: -0.753631767954211                              \n","                                                                                   \n","Trial completed:\n","Params: {'C': 0.0413160127964298, 'class_weight': 'balanced', 'max_iter': 3500, 'penalty': 'l2', 'solver': 'saga'} features:30000\n","Accuracy: 0.3846046925751996, Loss: -0.3846046925751996                            \n","                                                                                   \n","Trial completed:\n","Params: {'C': 1.2866174271619357, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:8000\n","Accuracy: 0.7497335036793144, Loss: -0.7497335036793144                            \n","                                                                                   \n","Trial completed:\n","Params: {'C': 8.258504696406298, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'lbfgs'} features:33000\n","Accuracy: 0.7469269519811088, Loss: -0.7469269519811088                            \n","                                                                                   \n","Trial completed:\n","Params: {'C': 5.159631745955403, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'newton-cg'} features:22000\n","Accuracy: 0.674749843803971, Loss: -0.674749843803971                              \n","100%|██████████| 50/50 [1:36:42<00:00, 116.05s/trial, best loss: -0.753791404361909]\n","Best hyperparameters: {'C': 5.763497554959019, 'class_weight': 1, 'k': 7, 'max_iter': 10, 'penalty': 0, 'solver': 2}\n"]}],"source":["best_bigram = logistic_hyperparameter((2,2))"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24882,"status":"ok","timestamp":1711640199851,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"Dg4s8GD8iLIx","outputId":"f848f227-d6e9-4ab2-8087-74b93f049936"},"outputs":[],"source":["# class_weights = {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}\n","# classifier = LogisticRegression(max_iter=1000,penalty=\"l2\",C=0.13,solver= \"liblinear\" ,class_weight=class_weights)\n","# model = create_pipeline(classifier, TfidfVectorizer(ngram_range=(2,2)),k=20000)\n","# model.fit(X_train,y_train)\n","# y_pred = model.predict(X_test)\n","# print(classification_report(y_pred,y_test))"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                      \n","Trial completed:\n","Params: {'C': 0.058289895913767396, 'class_weight': 'balanced', 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs'} features:34000\n","Accuracy: 0.7347223619056313, Loss: -0.7347223619056313\n","                                                                                 \n","Trial completed:\n","Params: {'C': 0.03903708093319761, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'newton-cg'} features:32000\n","Accuracy: 0.7375803980256309, Loss: -0.7375803980256309                          \n","  4%|▍         | 2/50 [02:19<55:43, 69.65s/trial, best loss: -0.7375803980256309]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                 \n","Trial completed:\n","Params: {'C': 0.18249196016486885, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'saga'} features:31000\n","Accuracy: 0.22462090468592036, Loss: -0.22462090468592036                        \n","                                                                                    \n","Trial completed:\n","Params: {'C': 3.736569136785883, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:28000\n","Accuracy: 0.7413859701072868, Loss: -0.7413859701072868                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.18554521289410605, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'lbfgs'} features:22000\n","Accuracy: 0.7395630040603416, Loss: -0.7395630040603416                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.340837373037037, 'class_weight': 'balanced', 'max_iter': 5000, 'penalty': 'l2', 'solver': 'lbfgs'} features:28000\n","Accuracy: 0.736251798607731, Loss: -0.736251798607731                               \n","                                                                                    \n","Trial completed:\n","Params: {'C': 2.0179039256411277, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'newton-cg'} features:10000\n","Accuracy: 0.7409894461954047, Loss: -0.7409894461954047                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.4325673810545323, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'lbfgs'} features:17000\n","Accuracy: 0.7376318969002903, Loss: -0.7376318969002903                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.0643459423219102, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'lbfgs'} features:23000\n","Accuracy: 0.7363650913055204, Loss: -0.7363650913055204                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.4391868208236744, 'class_weight': 'balanced', 'max_iter': 7000, 'penalty': 'l2', 'solver': 'liblinear'} features:12000\n","Accuracy: 0.7394136640596602, Loss: -0.7394136640596602                             \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.09060175860617785, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:17000\n","Accuracy: 0.7373435158252507, Loss: -0.7373435158252507                              \n"," 22%|██▏       | 11/50 [39:16<1:12:05, 110.92s/trial, best loss: -0.7413859701072868]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 0.8710779667823757, 'class_weight': 'balanced', 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga'} features:34000\n","Accuracy: 0.48296893462769114, Loss: -0.48296893462769114                            \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.24404376189667615, 'class_weight': 'balanced', 'max_iter': 4500, 'penalty': 'l2', 'solver': 'newton-cg'} features:25000\n","Accuracy: 0.7363238944068714, Loss: -0.7363238944068714                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 2.3028387280970564, 'class_weight': 'balanced', 'max_iter': 2500, 'penalty': 'l2', 'solver': 'lbfgs'} features:14000\n","Accuracy: 0.7378378824542959, Loss: -0.7378378824542959                              \n"," 28%|██▊       | 14/50 [47:40<1:16:38, 127.75s/trial, best loss: -0.7413859701072868]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 6.6999738153999076, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'saga'} features:8000\n","Accuracy: 0.34650123023122636, Loss: -0.34650123023122636                              \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.01472642641734602, 'class_weight': 'balanced', 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga'} features:12000\n","Accuracy: 0.7378996761448307, Loss: -0.7378996761448307                                \n"," 32%|███▏      | 16/50 [1:03:31<2:32:53, 269.81s/trial, best loss: -0.7413859701072868]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                       \n","Trial completed:\n","Params: {'C': 0.02242560894880751, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'saga'} features:32000\n","Accuracy: 0.5967801495190835, Loss: -0.5967801495190835                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.2690127950383542, 'class_weight': 'balanced', 'max_iter': 3000, 'penalty': 'l2', 'solver': 'newton-cg'} features:22000\n","Accuracy: 0.736823407184201, Loss: -0.736823407184201                                  \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.010754853280300881, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'lbfgs'} features:34000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.06382134901093246, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'newton-cg'} features:8000\n","Accuracy: 0.738764811149054, Loss: -0.738764811149054                                  \n","                                                                                       \n","Trial completed:\n","Params: {'C': 9.429738693433904, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:10000\n","Accuracy: 0.7411027386280038, Loss: -0.7411027386280038                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 8.080193351500048, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7412160315909834, Loss: -0.7412160315909834                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 4.572641412766868, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7414477652563675, Loss: -0.7414477652563675                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 3.051592319962745, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:29000\n","Accuracy: 0.74138082051153, Loss: -0.74138082051153                                  \n","                                                                                     \n","Trial completed:\n","Params: {'C': 4.265731638908409, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'} features:15000\n","Accuracy: 0.7413344736193391, Loss: -0.7413344736193391                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.5957353598782729, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} features:13000\n","Accuracy: 0.7388163082999772, Loss: -0.7388163082999772                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 4.70335100410847, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7414580643152859, Loss: -0.7414580643152859                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 6.177821351004255, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7412726775420927, Loss: -0.7412726775420927                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.9877551796634731, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7398256363610272, Loss: -0.7398256363610272                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 4.914840246232006, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:26000\n","Accuracy: 0.741391118907473, Loss: -0.741391118907473                               \n","                                                                                    \n","Trial completed:\n","Params: {'C': 2.382474228969387, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'liblinear'} features:33000\n","Accuracy: 0.741277828066015, Loss: -0.741277828066015                               \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.5259277124108537, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'} features:27000\n","Accuracy: 0.7387133163848425, Loss: -0.7387133163848425                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.576968457563038, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'liblinear'} features:18000\n","Accuracy: 0.7406341254141411, Loss: -0.7406341254141411                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.12021176626533557, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:19000\n","Accuracy: 0.7374259094899533, Loss: -0.7374259094899533                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 9.23053558365859, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'liblinear'} features:21000\n","Accuracy: 0.741319023638713, Loss: -0.741319023638713                               \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.8536527895527829, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'newton-cg'} features:16000\n","Accuracy: 0.7411645347052502, Loss: -0.7411645347052502                             \n"," 72%|███████▏  | 36/50 [1:39:12<12:10, 52.21s/trial, best loss: -0.7414580643152859]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                    \n","Trial completed:\n","Params: {'C': 3.182841049815473, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'} features:11000\n","Accuracy: 0.7401191566894061, Loss: -0.7401191566894061                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.03408896848731922, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:20000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.3876573845172838, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'lbfgs'} features:9000\n","Accuracy: 0.7402221533779642, Loss: -0.7402221533779642                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 4.783475979665902, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'newton-cg'} features:24000\n","Accuracy: 0.7407783134323542, Loss: -0.7407783134323542                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.2814701249158051, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7402685042480082, Loss: -0.7402685042480082                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.13910128340209368, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'liblinear'} features:23000\n","Accuracy: 0.7374619566602505, Loss: -0.7374619566602505                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.7029103071110056, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'lbfgs'} features:31000\n","Accuracy: 0.7411593860376592, Loss: -0.7411593860376592                             \n"," 86%|████████▌ | 43/50 [1:46:12<05:47, 49.70s/trial, best loss: -0.7414580643152859]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                    \n","Trial completed:\n","Params: {'C': 2.1993854912077193, 'class_weight': 'balanced', 'max_iter': 5500, 'penalty': 'l2', 'solver': 'saga'} features:30000\n","Accuracy: 0.600338518595845, Loss: -0.600338518595845                               \n","                                                                                     \n","Trial completed:\n","Params: {'C': 1.6529598295798145, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear'} features:33000\n","Accuracy: 0.7407062204177108, Loss: -0.7407062204177108                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 6.400163915962933, 'class_weight': 'balanced', 'max_iter': 7000, 'penalty': 'l2', 'solver': 'newton-cg'} features:28000\n","Accuracy: 0.7362363488922952, Loss: -0.7362363488922952                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 1.100880825418966, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'lbfgs'} features:25000\n","Accuracy: 0.7411799841554959, Loss: -0.7411799841554959                              \n"," 94%|█████████▍| 47/50 [2:02:10<06:19, 126.54s/trial, best loss: -0.7414580643152859]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 3.535794173441978, 'class_weight': 'balanced', 'max_iter': 6000, 'penalty': 'l2', 'solver': 'saga'} features:14000\n","Accuracy: 0.7379872208638363, Loss: -0.7379872208638363                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.21273790237230233, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:32000\n","Accuracy: 0.7375803981582261, Loss: -0.7375803981582261                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.33439523132553495, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'newton-cg'} features:17000\n","Accuracy: 0.7404847864742203, Loss: -0.7404847864742203                              \n","100%|██████████| 50/50 [2:18:59<00:00, 166.80s/trial, best loss: -0.7414580643152859]\n","Best hyperparameters: {'C': 4.70335100410847, 'class_weight': 1, 'k': 22, 'max_iter': 5, 'penalty': 0, 'solver': 2}\n"]}],"source":["best_trigram = logistic_hyperparameter((3,3))"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29928,"status":"ok","timestamp":1711640232041,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"dgQg1etaiLIx","outputId":"d4f0f6a9-2753-4025-a915-f1fbfc3c23c2"},"outputs":[],"source":["# class_weights = {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}\n","# classifier = LogisticRegression(max_iter=1000,penalty=\"l2\",C=0.13,solver= \"liblinear\" ,class_weight=class_weights)\n","# model = create_pipeline(classifier, TfidfVectorizer(ngram_range=(3,3)))\n","# model.fit(X_train,y_train)\n","# y_pred = model.predict(X_test)\n","# print(classification_report(y_pred,y_test))"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                      \n","Trial completed:\n","Params: {'C': 0.01207889878698062, 'class_weight': 'balanced', 'max_iter': 4500, 'penalty': 'l2', 'solver': 'lbfgs'} features:14000\n","Accuracy: 0.5916143652270378, Loss: -0.5916143652270378\n","                                                                                   \n","Trial completed:\n","Params: {'C': 3.8492224818563643, 'class_weight': 'balanced', 'max_iter': 4500, 'penalty': 'l2', 'solver': 'newton-cg'} features:11000\n","Accuracy: 0.6177744345868963, Loss: -0.6177744345868963                            \n","                                                                                    \n","Trial completed:\n","Params: {'C': 5.242654732993984, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'lbfgs'} features:26000\n","Accuracy: 0.7602335945314855, Loss: -0.7602335945314855                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.21544206332897403, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'liblinear'} features:20000\n","Accuracy: 0.7613356004655059, Loss: -0.7613356004655059                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.03099063937156309, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'liblinear'} features:32000\n","Accuracy: 0.7383940380004524, Loss: -0.7383940380004524                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 5.079376148348978, 'class_weight': 'balanced', 'max_iter': 5000, 'penalty': 'l2', 'solver': 'newton-cg'} features:9000\n","Accuracy: 0.6178465277341346, Loss: -0.6178465277341346                             \n"," 12%|█▏        | 6/50 [12:45<1:25:43, 116.90s/trial, best loss: -0.7613356004655059]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                    \n","Trial completed:\n","Params: {'C': 0.8433767475287668, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'saga'} features:17000\n","Accuracy: 0.7431625241578486, Loss: -0.7431625241578486                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.040800234413865245, 'class_weight': 'balanced', 'max_iter': 5000, 'penalty': 'l2', 'solver': 'liblinear'} features:13000\n","Accuracy: 0.7540282984958481, Loss: -0.7540282984958481                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.16205011550226944, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'liblinear'} features:34000\n","Accuracy: 0.759342698554159, Loss: -0.759342698554159                               \n"," 18%|█▊        | 9/50 [43:37<3:50:40, 337.57s/trial, best loss: -0.7613356004655059]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                    \n","Trial completed:\n","Params: {'C': 1.6312778270881716, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'saga'} features:18000\n","Accuracy: 0.6426354049488652, Loss: -0.6426354049488652                               \n","                                                                                       \n","Trial completed:\n","Params: {'C': 2.002552087472043, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg'} features:21000\n","Accuracy: 0.7627878009217701, Loss: -0.7627878009217701                                \n"," 22%|██▏       | 11/50 [1:16:06<6:25:10, 592.58s/trial, best loss: -0.7627878009217701]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                       \n","Trial completed:\n","Params: {'C': 4.461486156367735, 'class_weight': 'balanced', 'max_iter': 7500, 'penalty': 'l2', 'solver': 'saga'} features:31000\n","Accuracy: 0.6276308592508448, Loss: -0.6276308592508448                                \n","                                                                                         \n","Trial completed:\n","Params: {'C': 0.03548594925416224, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs'} features:34000\n","Accuracy: 0.758091341348874, Loss: -0.758091341348874                                    \n"," 26%|██▌       | 13/50 [2:17:51<11:06:24, 1080.66s/trial, best loss: -0.7627878009217701]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                         \n","Trial completed:\n","Params: {'C': 0.13718795760253605, 'class_weight': 'balanced', 'max_iter': 5500, 'penalty': 'l2', 'solver': 'saga'} features:26000\n","Accuracy: 0.6073464587601545, Loss: -0.6073464587601545                                  \n","                                                                                         \n","Trial completed:\n","Params: {'C': 0.1290439170509858, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4500, 'penalty': 'l2', 'solver': 'lbfgs'} features:27000\n","Accuracy: 0.766047512803525, Loss: -0.766047512803525                                    \n"," 30%|███       | 15/50 [3:00:00<10:27:57, 1076.50s/trial, best loss: -0.766047512803525] "]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                        \n","Trial completed:\n","Params: {'C': 5.882685065241288, 'class_weight': 'balanced', 'max_iter': 4000, 'penalty': 'l2', 'solver': 'saga'} features:21000\n","Accuracy: 0.602057620782302, Loss: -0.602057620782302                                   \n","                                                                                        \n","Trial completed:\n","Params: {'C': 1.250620188589755, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'liblinear'} features:24000\n","Accuracy: 0.7679837703549037, Loss: -0.7679837703549037                                 \n","                                                                                        \n","Trial completed:\n","Params: {'C': 0.018229761876628926, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'liblinear'} features:24000\n","Accuracy: 0.7372662716237095, Loss: -0.7372662716237095                                \n"," 36%|███▌      | 18/50 [3:35:49<6:13:28, 700.25s/trial, best loss: -0.7679837703549037]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                       \n","Trial completed:\n","Params: {'C': 1.1940526136803948, 'class_weight': 'balanced', 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga'} features:13000\n","Accuracy: 0.49479681315058216, Loss: -0.49479681315058216                              \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.014058322327067269, 'class_weight': 'balanced', 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:11000\n","Accuracy: 0.7393209700100879, Loss: -0.7393209700100879                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.5003069328077953, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'lbfgs'} features:23000\n","Accuracy: 0.7657282357450861, Loss: -0.7657282357450861                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.07330524025831088, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3000, 'penalty': 'l2', 'solver': 'lbfgs'} features:27000\n","Accuracy: 0.7638692157654938, Loss: -0.7638692157654938                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.3595007358988325, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'lbfgs'} features:27000\n","Accuracy: 0.7657694355608271, Loss: -0.7657694355608271                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.531345407812861, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'liblinear'} features:22000\n","Accuracy: 0.7664079813242142, Loss: -0.7664079813242142                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 9.27646156127559, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'liblinear'} features:22000\n","Accuracy: 0.7658054791510566, Loss: -0.7658054791510566                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 0.7679983433015344, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7000, 'penalty': 'l2', 'solver': 'liblinear'} features:10000\n","Accuracy: 0.7663358873814051, Loss: -0.7663358873814051                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 2.5108649840108233, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7675563492662663, Loss: -0.7675563492662663                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 2.6200949029875567, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} features:30000\n","Accuracy: 0.7675357519440003, Loss: -0.7675357519440003                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 9.016708708651354, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} features:16000\n","Accuracy: 0.7657951765120707, Loss: -0.7657951765120707                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 2.4901891355452848, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:33000\n","Accuracy: 0.7678910767031167, Loss: -0.7678910767031167                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 1.3287379432315805, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'newton-cg'} features:33000\n","Accuracy: 0.7640134145239097, Loss: -0.7640134145239097                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 3.1765593985109026, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:15000\n","Accuracy: 0.7671804241351966, Loss: -0.7671804241351966                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 0.30427743399808943, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'newton-cg'} features:24000\n","Accuracy: 0.7664337319548997, Loss: -0.7664337319548997                             \n","                                                                                    \n","Trial completed:\n","Params: {'C': 1.0087106823091132, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:28000\n","Accuracy: 0.767818982892903, Loss: -0.767818982892903                               \n","                                                                                     \n","Trial completed:\n","Params: {'C': 6.570158759525809, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'liblinear'} features:33000\n","Accuracy: 0.7667530102066945, Loss: -0.7667530102066945                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 1.7672082604956019, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6500, 'penalty': 'l2', 'solver': 'newton-cg'} features:8000\n","Accuracy: 0.7629062368507515, Loss: -0.7629062368507515                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.5548532241006532, 'class_weight': 'balanced', 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear'} features:12000\n","Accuracy: 0.7358964790198232, Loss: -0.7358964790198232                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.2532248396724721, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 6000, 'penalty': 'l2', 'solver': 'liblinear'} features:14000\n","Accuracy: 0.762195588128089, Loss: -0.762195588128089                               \n","                                                                                    \n","Trial completed:\n","Params: {'C': 4.05505917074005, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 3500, 'penalty': 'l2', 'solver': 'liblinear'} features:25000\n","Accuracy: 0.7676078454890238, Loss: -0.7676078454890238                             \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.7767026258234296, 'class_weight': 'balanced', 'max_iter': 3000, 'penalty': 'l2', 'solver': 'newton-cg'} features:19000\n","Accuracy: 0.6151790233422569, Loss: -0.6151790233422569                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.059547803941541765, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5500, 'penalty': 'l2', 'solver': 'liblinear'} features:29000\n","Accuracy: 0.7445838865747708, Loss: -0.7445838865747708                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 7.230230375734248, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'liblinear'} features:20000\n","Accuracy: 0.7662637935711911, Loss: -0.7662637935711911                             \n"," 84%|████████▍ | 42/50 [4:20:32<14:09, 106.16s/trial, best loss: -0.7679837703549037]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 2.1314860600784398, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 4000, 'penalty': 'l2', 'solver': 'saga'} features:17000\n","Accuracy: 0.7435746836834917, Loss: -0.7435746836834917                              \n","                                                                                       \n","Trial completed:\n","Params: {'C': 3.759068702544039, 'class_weight': 'balanced', 'max_iter': 6000, 'penalty': 'l2', 'solver': 'lbfgs'} features:32000\n","Accuracy: 0.6227798736178591, Loss: -0.6227798736178591                                \n","                                                                                       \n","Trial completed:\n","Params: {'C': 1.3116980592369556, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 5000, 'penalty': 'l2', 'solver': 'newton-cg'} features:24000\n","Accuracy: 0.7640803533019678, Loss: -0.7640803533019678                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.17542042897340338, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'} features:33000\n","Accuracy: 0.7597752652607002, Loss: -0.7597752652607002                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.10313069815211577, 'class_weight': 'balanced', 'max_iter': 4000, 'penalty': 'l2', 'solver': 'saga'} features:9000\n","Accuracy: 0.6021504955589905, Loss: -0.6021504955589905                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 0.3909351004975028, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear'} features:18000\n","Accuracy: 0.7650021357158467, Loss: -0.7650021357158467                              \n","                                                                                     \n","Trial completed:\n","Params: {'C': 5.097539945873237, 'class_weight': {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}, 'max_iter': 7500, 'penalty': 'l2', 'solver': 'lbfgs'} features:24000\n","Accuracy: 0.7605065192613345, Loss: -0.7605065192613345                              \n"," 98%|█████████▊| 49/50 [5:09:43<04:00, 240.93s/trial, best loss: -0.7679837703549037]"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n","c:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","\n"]},{"name":"stdout","output_type":"stream","text":["                                                                                     \n","Trial completed:\n","Params: {'C': 0.9347793345566694, 'class_weight': 'balanced', 'max_iter': 5500, 'penalty': 'l2', 'solver': 'saga'} features:23000\n","Accuracy: 0.5576676628894262, Loss: -0.5576676628894262                              \n","100%|██████████| 50/50 [5:46:09<00:00, 415.38s/trial, best loss: -0.7679837703549037]\n","Best hyperparameters: {'C': 1.250620188589755, 'class_weight': 1, 'k': 16, 'max_iter': 6, 'penalty': 0, 'solver': 2}\n"]}],"source":["best_n_gram = logistic_hyperparameter((1,3))"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58372,"status":"ok","timestamp":1711640330945,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"xFn2Jv9xiLIx","outputId":"b3df71ff-2384-4e13-9939-23bd23e57d21"},"outputs":[],"source":["# class_weights = {1: 7, 2: 12, 3: 9, 4: 8, 5: 7}\n","# classifier = LogisticRegression(max_iter=1000,penalty=\"l2\",C=0.13,solver= \"liblinear\" ,class_weight=class_weights)\n","# model = create_pipeline(classifier, TfidfVectorizer(ngram_range=(1,3)),k=24500)\n","# model.fit(X_train,y_train)\n","# y_pred = model.predict(X_test)\n","# print(classification_report(y_pred,y_test))"]},{"cell_type":"markdown","metadata":{"id":"AGLtMM6RiLIy"},"source":["## XGBoost"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":434,"status":"ok","timestamp":1711640341579,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"jG_yRRt7iLIy"},"outputs":[],"source":["# sampling_strategy = {i: 23000 for i in range(1, 4)}\n","# undersampler = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n","# X_train, y_train= undersampler.fit_resample(X_train, y_train)\n","\n","# y_train_adjusted = y_train-1\n","# y_test = y_test-1"]},{"cell_type":"markdown","metadata":{"id":"lDGxFIVLiLIy"},"source":["### NGram"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":666,"status":"ok","timestamp":1711640346291,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"SnYhBcr_iLIy"},"outputs":[],"source":["# space = {\n","#     'max_depth': hp.choice('max_depth', np.arange(3, 11, dtype=int)),\n","#     'n_estimators': hp.choice('n_estimators', np.arange(100, 1001, 100, dtype=int)),\n","#     'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n","#     'subsample': hp.uniform('subsample', 0.5, 1.0),\n","#     'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n","#     'min_child_weight': hp.choice('min_child_weight', np.arange(1, 11, dtype=int)),\n","#     'reg_lambda': hp.uniform('reg_lambda', 1, 100),\n","#     'k': hp.choice('k', np.arange(8000, 17000, 500, dtype=int))\n","# }\n","\n","# def objective(params):\n","#     k = params.pop('k')\n","#     feature_selector = SelectKBest(chi2, k=k)\n","#     X_train_sel = feature_selector.fit_transform(X_train, y_train)\n","#     X_test_sel = feature_selector.transform(X_test)\n","#     clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', **params)\n","#     score = cross_val_score(clf, X_train_sel, y_train_adjusted, scoring='accuracy', cv=5).mean()\n","#     print(f\"\\nTrial completed:\")\n","#     print(f\"Params: {params} features:{k}\")\n","#     print(f\"Accuracy: {score}, Loss: {-score}\")\n","#     return {'loss': -score, 'status': STATUS_OK}\n","# # Run the optimization\n","# trials = Trials()\n","# best = fmin(fn=objective,\n","#             space=space,\n","#             algo=tpe.suggest,\n","#             max_evals=50,\n","#             trials=trials)\n","\n","# print(\"Best hyperparameters:\", best)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":162800,"status":"error","timestamp":1711642020150,"user":{"displayName":"Sai Nikhita","userId":"01344125893615558680"},"user_tz":-240},"id":"VIlhdGlGiLIy","outputId":"6b70aa6c-3d3d-4bf6-d6b9-2461cf1665b8"},"outputs":[],"source":["# params = {'colsample_bytree': 0.8230008586447808,\n","#  'learning_rate': 0.1909617073607323,\n","#  'max_depth': 10,\n","#  'min_child_weight': 4,\n","#  'n_estimators': 1000,\n","#  'reg_lambda': 4.163618957089685,\n","#  'subsample': 0.59102293915828 }\n","\n","# classifier =  xgb.XGBClassifier(eval_metric='mlogloss', **params)\n","\n","# model = create_pipeline(classifier, TfidfVectorizer(ngram_range=(1,3)),k=10500)\n","# model.fit(X_train,y_train_adjusted)\n","# y_pred = model.predict(X_test)\n","# print(classification_report(y_pred,y_test))\n","# y_test = y_test+1"]},{"cell_type":"markdown","metadata":{"id":"p9zpi0t4iLIy"},"source":["### Googles Word2Vec"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# google_word2vec = KeyedVectors.load_word2vec_format(\"../Amazon-Reviews/GoogleNews-vectors-negative300.bin\", binary=True)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# def document_vector(word2vec_model, doc_tokens):\n","#     tokens = [token for token in doc_tokens if token in word2vec_model.key_to_index]\n","#     if not tokens:\n","#         return np.zeros(word2vec_model.vector_size)\n","#     doc_vector = np.mean(word2vec_model[tokens], axis=0)\n","#     return doc_vector"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# X_train = np.array([document_vector(google_word2vec,doc) for doc in X_train])\n","# X_test = np.array([document_vector(google_word2vec,doc) for doc in X_test])\n","# sampling_strategy = {i: 23000 for i in range(1, 4)}\n","# undersampler = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n","# X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# y_train_under = y_train_under-1"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["# space = {\n","#     'max_depth': hp.choice('max_depth', np.arange(3, 11, dtype=int)),\n","#     'n_estimators': hp.choice('n_estimators', np.arange(100, 1001, 100, dtype=int)),\n","#     'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n","#     'subsample': hp.uniform('subsample', 0.5, 1.0),\n","#     'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n","#     'min_child_weight': hp.choice('min_child_weight', np.arange(1, 11, dtype=int)),\n","#     'reg_lambda': hp.uniform('reg_lambda', 1, 100),\n","# }\n","\n","# def objective(params):\n","#     clf = xgb.XGBClassifier(eval_metric='mlogloss', **params)\n","#     score = cross_val_score(clf, X_train_under, y_train_under, scoring='accuracy', cv=5).mean()\n","#     print(f\"\\nTrial completed:\")\n","#     print(f\"Params: {params} features:{k}\")\n","#     print(f\"Accuracy: {score}, Loss: {-score}\")\n","#     return {'loss': -score, 'status': STATUS_OK}\n","# # Run the optimization\n","# trials = Trials()\n","# best = fmin(fn=objective,\n","#             space=space,\n","#             algo=tpe.suggest,\n","#             max_evals=50,\n","#             trials=trials)\n","\n","# print(\"Best hyperparameters:\", best)"]},{"cell_type":"markdown","metadata":{"id":"O29q4IZ_iLIy"},"source":["## Random Forest Classifier"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original class distribution: Counter({5: 143171, 4: 25754, 3: 12802, 1: 6567, 2: 5895})\n"]}],"source":["train = pd.read_csv(\"./train.csv\")\n","test = pd.read_csv(\"./test.csv\")\n","train = train.drop_duplicates()\n","train[\"Review\"]= train[\"Review\"].astype(str)\n","train[\"Review\"] = train[\"Review\"].apply(preprocess)\n","y = train[\"overall\"]\n","X_train, X_test, y_train, y_test = train_test_split(train[\"Review\"], y, stratify=y,test_size=0.3, random_state=42)\n","print('Original class distribution:', Counter(y_train))"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                      \n","Trial completed:\n","Params: {'max_depth': 60, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1200} features:12000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228\n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 19, 'n_estimators': 1500} features:9000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                             \n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 25, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 17, 'n_estimators': 600} features:8000\n","Accuracy: 0.7372817204109795, Loss: -0.7372817204109795                             \n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 700} features:12000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                             \n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 18, 'n_estimators': 100} features:9000\n","Accuracy: 0.7379563193114431, Loss: -0.7379563193114431                             \n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 55, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 9, 'n_estimators': 1400} features:13000\n","Accuracy: 0.7374722561169543, Loss: -0.7374722561169543                             \n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 700} features:15000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                             \n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 70, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 800} features:18000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                             \n","                                                                                    \n","Trial completed:\n","Params: {'max_depth': 90, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 800} features:11000\n","Accuracy: 0.7399440737485546, Loss: -0.7399440737485546                               \n","                                                                                      \n","Trial completed:\n","Params: {'max_depth': 25, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 600} features:18000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                               \n","                                                                                       \n","Trial completed:\n","Params: {'max_depth': 25, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 1100} features:19000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                                \n","                                                                                       \n","Trial completed:\n","Params: {'max_depth': 90, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 700} features:8000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                                \n","                                                                                       \n","Trial completed:\n","Params: {'max_depth': 95, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 11, 'n_estimators': 1200} features:13000\n","Accuracy: 0.7403354451475879, Loss: -0.7403354451475879                                \n","                                                                                        \n","Trial completed:\n","Params: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 1300} features:16000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                                 \n","                                                                                        \n","Trial completed:\n","Params: {'max_depth': 40, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 16, 'n_estimators': 1200} features:10000\n","Accuracy: 0.7372765708152228, Loss: -0.7372765708152228                                \n"," 30%|███       | 15/50 [6:54:55<16:08:09, 1659.69s/trial, best loss: -0.7403354451475879]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[47], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39mscore, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK}\n\u001b[0;32m     26\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m---> 27\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m random_forest_best \u001b[38;5;241m=\u001b[39m best\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(random_forest_best)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n","Cell \u001b[1;32mIn[47], line 20\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     17\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m create_pipeline(classifier, vectorizer,Normalizer(norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m) ,feature_selection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m---> 20\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTrial completed:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\blobb\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["space = {\n","    'n_estimators': hp.choice('n_estimators', np.arange(100, 1501, 100, dtype=int)),\n","    'max_depth': hp.quniform('max_depth', 5, 100, 5),  \n","    'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1), \n","    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1), \n","    'max_features': hp.choice('max_features', [ 'sqrt', 'log2', None]),\n","    'k': hp.choice('k', np.arange(8000, 20000, 1000, dtype=int)),\n","}\n","\n","def objective(params):\n","    params['max_depth'] = int(params['max_depth'])\n","    params['min_samples_split'] = int(params['min_samples_split'])\n","    params['min_samples_leaf'] = int(params['min_samples_leaf'])\n","\n","    k = params.pop('k')\n","    classifier = RandomForestClassifier(**params)\n","    vectorizer = CountVectorizer()\n","\n","    model = create_pipeline(classifier, vectorizer,Normalizer(norm='l2') ,feature_selection=True, k=k)\n","    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n","    print(f\"\\nTrial completed:\")\n","    print(f\"Params: {params} features:{k}\")\n","    print(f\"Accuracy: {score}, Loss: {-score}\")\n","    return {'loss': -score, 'status': STATUS_OK}\n","\n","trials = Trials()\n","best = fmin(fn=objective,\n","            space=space,\n","            algo=tpe.suggest,\n","            max_evals=50,\n","            trials=trials)\n","random_forest_best = best\n","print(random_forest_best)\n","print(\"Best hyperparameters:\", best)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-Hlxka8iLIy"},"outputs":[],"source":["# classifier =  RandomForestClassifier()\n","# model = create_pipeline(classifier,CountVectorizer(),Normalizer(norm='l2'))\n","# model.fit(X_train,y_train)\n","# y_pred = model.predict(X_test)\n","# print(classification_report(y_pred,y_test))\n","# y_pred = model.predict(X_train)\n","# print(classification_report(y_pred,y_train))"]},{"cell_type":"markdown","metadata":{"id":"mBRun7CBwKou"},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["space = {\n","    'alpha': hp.loguniform('alpha', np.log(0.0001), np.log(0.1)),\n","    'penalty': hp.choice('penalty', ['l2', 'l1', 'elasticnet']),\n","    'loss': hp.choice('loss', ['hinge', 'log_loss', 'modified_huber']),\n","    'max_iter': hp.choice('max_iter', np.arange(1000, 12000, 1000, dtype=int)),\n","    'learning_rate': hp.choice('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive']),\n","    'eta0': hp.loguniform('eta0', np.log(0.01), np.log(1)),\n","    'k': hp.choice('k', np.arange(8000, 20000, 1000, dtype=int)),\n","}\n","\n","def objective(params):\n","    k = params.pop('k')\n","    classifier = SGDClassifier(**params)\n","    vectorizer = CountVectorizer(binary = True)\n","\n","    model = create_pipeline(classifier, vectorizer,Normalizer(norm='l2') ,feature_selection=True, k=k)\n","    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n","    print(f\"\\nTrial completed:\")\n","    print(f\"Params: {params} features:{k}\")\n","    print(f\"Accuracy: {score}, Loss: {-score}\")\n","    return {'loss': -score, 'status': STATUS_OK}\n","\n","trials = Trials()\n","best = fmin(fn=objective,\n","            space=space,\n","            algo=tpe.suggest,\n","            max_evals=50,\n","            trials=trials)\n","\n","print(\"Best hyperparameters:\", best)"]},{"cell_type":"markdown","metadata":{},"source":["# Sequence Model"]},{"cell_type":"markdown","metadata":{},"source":["## Bi-Directional LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## LSTM"]},{"cell_type":"markdown","metadata":{},"source":["## Transformers"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
